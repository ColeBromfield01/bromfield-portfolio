{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJ+gtbka4Lf1nhEbj5gAIq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ColeBromfield01/bromfield-portfolio/blob/main/DATA604_Homework_11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first step is to import the USPS dataset.  This can be done through scikit-learn."
      ],
      "metadata": {
        "id": "GjQQxdcPv1hj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5CzVEu2aNCo",
        "outputId": "ac676925-cdb4-4d70-d65a-5dc475a2209f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "# Load USPS dataset\n",
        "usps = fetch_openml('usps', version=2)\n",
        "\n",
        "# Access the data and labels\n",
        "X = usps.data\n",
        "y = usps.target"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the dataset has been imported, we can set up our kernel PCA transformation.  With the high dimensionality of the dataset, I determined RBF to be the most appropriate kernel method.  RBF is less reliant on underlying patterns in the data, which would have been difficult to determine in this case."
      ],
      "metadata": {
        "id": "3wM0WzSHscxZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import KernelPCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    usps.data, usps.target, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "kpca = KernelPCA(kernel='rbf', gamma=0.03)\n",
        "kpca.fit(X_train)\n",
        "\n",
        "X_train_kpca = kpca.transform(X_train)\n",
        "X_test_kpca = kpca.transform(X_test)"
      ],
      "metadata": {
        "id": "VMLo1QhIaird"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the data transformed, we can now perform kNN with k = 20."
      ],
      "metadata": {
        "id": "XsSn8553wAeY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "k = 20\n",
        "knn = KNeighborsClassifier(n_neighbors=k)\n",
        "knn.fit(X_train_kpca, y_train)\n",
        "\n",
        "y_pred = knn.predict(X_test_kpca)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1clOvdwwaiqo",
        "outputId": "1f5c3b05-7faf-43e0-e04a-2ed9353f3794"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9483870967741935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see a very high accuracy with this method, at nearly 95%.  To determine how significantly we can lower the dimensionality, we can use an iterative method such as bisection.  With this method, we can calculate the smallest number of principal components that can be kept without the accuracy dropping below a certain threshold.  Since we don't want to lose too much accuracy, let's set that threshold at 94%."
      ],
      "metadata": {
        "id": "98DexAN23Qmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = 1\n",
        "end = X_train_kpca.shape[1]\n",
        "min_dimensionality = None\n",
        "final_accuracy = None\n",
        "accuracy_threshold = 0.94\n",
        "\n",
        "# Perform bisection method\n",
        "while start < end:\n",
        "    mid = (start + end) // 2\n",
        "\n",
        "    X_train_kpca_reduced = X_train_kpca[:, :mid]\n",
        "    X_test_kpca_reduced = X_test_kpca[:, :mid]\n",
        "\n",
        "    knn.fit(X_train_kpca_reduced, y_train)\n",
        "    y_pred = knn.predict(X_test_kpca_reduced)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    if accuracy >= accuracy_threshold:\n",
        "        min_dimensionality = mid\n",
        "        final_accuracy = accuracy\n",
        "        end = mid\n",
        "    else:\n",
        "        start = mid + 1\n",
        "\n",
        "# Print the final dimensionality and accuracy\n",
        "print(\"Final Dimensionality:\", min_dimensionality)\n",
        "print(\"Final Accuracy:\", final_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SM-EnS3GxKrR",
        "outputId": "23faa1ad-9aec-4873-98a6-b2c6333e60d8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Dimensionality: 45\n",
            "Final Accuracy: 0.9424731182795699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Surprisingly, the data can be reduced to 45 dimensions with less than a 1% drop in accuracy.  This is a significant drop from the 256 dimensions of the raw data (and even more so compared with the thousands of dimensions in the RBF-transformed data)."
      ],
      "metadata": {
        "id": "DWl0jO6x5m4a"
      }
    }
  ]
}